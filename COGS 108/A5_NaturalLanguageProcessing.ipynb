{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "aed67d76b742f360598b2c0f40b18b63",
     "grade": false,
     "grade_id": "cell-70c15471327b6620",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# COGS 108 - Assignment 5: Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e3e7571af26f93d210dfa32d3754b943",
     "grade": false,
     "grade_id": "cell-8499cb794c95ec9d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Important Reminders\n",
    "**You must submit this file (`A5_NLP.ipynb`) to TritonED to finish the homework.**\n",
    "\n",
    "- This assignment has hidden tests: tests that are not visible here, but that will be run on your submitted assignment for grading.\n",
    "    - This means passing all the tests you can see in the notebook here does not guarantee you have the right answer!\n",
    "    - In particular many of the tests you can see simply check that the right variable names exist. Hidden tests check the actual values. \n",
    "        - It is up to you to check the values, and make sure they seem reasonable.\n",
    "- A reminder to restart the kernel and re-run the code as a first line check if things seem to go weird.\n",
    "    - For example, note that some cells can only be run once, because they re-write a variable (for example, your dataframe), and change it in a way that means a second execution will fail. \n",
    "    - Also, running some cells out of order might change the dataframe in ways that may cause an error, which can be fixed by re-running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0b10d6b48490820c1f1a3b07406400fd",
     "grade": false,
     "grade_id": "cell-6b464efd2fb5aabd",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Background & Work Flow\n",
    "\n",
    "- In this homework assignment, we will be analyzing text data. A common approach to analyzing text data is to use methods that allow us to convert text data into some kind of numerical representation - since we can then use all of our mathematical tools on such data. In this assignment, we will explore 2 feature engineering methods that convert raw text data into numerical vectors:\n",
    "    - Bag of Words (BoW)\n",
    "        - BoW encodes an input sentence as the frequency of each word in the sentence. \n",
    "        - In this approach, all words contribute equally to the feature vectors.\n",
    "    - Term Frequency - Inverse Document Frequency (TF-IDF)\n",
    "        - TF-IDF is a measure of how important each term is to a specific document, as compared to an overall corpus. \n",
    "        - TF-IDF encodes a each word as the it's frequency in the document of interest, divided by a measure of how common the word is across all documents (the corpus).\n",
    "        - Using this approach each word contributes differently to the feature vectors.\n",
    "        - The assumption behind using TF-IDF is that words that appear commonly everywhere are not that informative about what is specifically interesting about a document of interest, so it is tuned to representing a document in terms of the words it uses that are different from other documents. \n",
    "\n",
    "- To compare those 2 methods, we will first apply them on the same Movie Review dataset to analyse sentiment (how positive or negative a text is). In order to make the comparison fair, the same SVM (support vector machine) classifier will be used to classify positive reviews and negative reviews.\n",
    "\n",
    "- SVM is a simple yet powerful and interpretable linear model. To use it as a classifier, we need to have at least 2 splits of the data: training data and test data. The training data is used to tune the weight parameters in the SVM to learn an optimal way to classify the training data. We can then test this trained SVM classifier on the test data, to see how well it works on data that the classifier has not seen before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ff20ecd9199338a27728c1306d2c51d6",
     "grade": false,
     "grade_id": "Imports",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Imports - these are all the imports needed for the assignment\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import nltk package \n",
    "#   PennTreeBank word tokenizer \n",
    "#   English language stopwords\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# scikit-learn imports\n",
    "#   SVM (Support Vector Machine) classifer \n",
    "#   Vectorizer, which that transforms text data into bag-of-words feature\n",
    "#   TF-IDF Vectorizer that first removes widely used words in the dataset and then transforms test data\n",
    "#   Metrics functions to evaluate performance\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d22183d219cc386a0cb84900e4711525",
     "grade": false,
     "grade_id": "cell-d96a6fcbdcbed177",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "For this assignemnt we will be using nltk: the Natural Language Toolkit.\n",
    "\n",
    "To do so, we will need to download some text data.\n",
    "\n",
    "Natural language processing (NLP) often requires corpus data (lists of words, and or example text data) which is what we will download here now, if you don't already have them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In the cell below, we will download some files from nltk. \n",
    "#   If you hit an error doing so, come back to this cell, and uncomment and run the code below. \n",
    "#   This code gives python permission to write to your disk (if it doesn't already have persmission to do so)\n",
    "\n",
    "# import ssl\n",
    "\n",
    "# try:\n",
    "#     _create_unverified_https_context = ssl._create_unverified_context\n",
    "# except AttributeError:\n",
    "#     pass\n",
    "# else:\n",
    "#     ssl._create_default_https_context = _create_unverified_https_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9f82bd6229164ec98da8b4dc9a3bf25e",
     "grade": false,
     "grade_id": "cell-04e576aebbcdfe34",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [WinError 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\zafri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the NLTK English tokenizer and the stopwords of all languages\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2583e3b70af931e62b8094e488d28f30",
     "grade": false,
     "grade_id": "cell-c728326960d37d88",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Part 1: Sentiment Analysis on Movie Review Data\n",
    "\n",
    "In part 1 we will apply sentiment analysis to Movie Review (MR) data.\n",
    "\n",
    "- The MR data contains more than 10,000 reviews collect from IMDB website, and each of the reviews is annotated as either positive or negative sample. The number of positive and negative reviews are roughly the same. For more information about the dataset, you can visit http://www.cs.cornell.edu/people/pabo/movie-review-data/\n",
    "\n",
    "- For this homework assignment, we've already shuffled the data, and truncated the data to contain only 5000 reviews.\n",
    "\n",
    "In this part of the assignment we will:\n",
    "- Transform the raw text data into vectors with the BoW encoding method\n",
    "- Split the data into training and test sets\n",
    "- Write a function to train an SVM classifier on the training set\n",
    "- Test this classifier on the test set and report the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a) Import data\n",
    "Import the textfile 'rt-polarity.txt' into a DataFrame called MR_df,\n",
    "\n",
    "Set the column names as `index`, `label`, `review`\n",
    "Note that 'rt-polarity.txt' is a tab separated raw text file, in which data is separated by tabs ('\\t')\n",
    "\n",
    "You can load this file with `read_csv`:\n",
    "- Specifying the `sep` (separator) argument as tabs ('\\t')\n",
    "- You will have the set 'header' as None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "3d7ae5b8848d690f43f4e2120d650071",
     "grade": false,
     "grade_id": "Q-1a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8477</td>\n",
       "      <td>neg</td>\n",
       "      <td>except as an acting exercise or an exceptional...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4031</td>\n",
       "      <td>pos</td>\n",
       "      <td>japanese director shohei imamura 's latest fil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10240</td>\n",
       "      <td>neg</td>\n",
       "      <td>i walked away not really know who `` they `` w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8252</td>\n",
       "      <td>neg</td>\n",
       "      <td>what could have been a neat little story about...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1346</td>\n",
       "      <td>pos</td>\n",
       "      <td>no screen fantasy-adventure in recent memory h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index label                                             review\n",
       "0   8477   neg  except as an acting exercise or an exceptional...\n",
       "1   4031   pos  japanese director shohei imamura 's latest fil...\n",
       "2  10240   neg  i walked away not really know who `` they `` w...\n",
       "3   8252   neg  what could have been a neat little story about...\n",
       "4   1346   pos  no screen fantasy-adventure in recent memory h..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MR_filepath='data/rt-polarity.tsv'\n",
    "\n",
    "# YOUR CODE HERE\n",
    "MR_df=pd.read_csv(MR_filepath, delimiter=\"\\t\",header=None, names=['index', 'label', 'review'])\n",
    "MR_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a2303784fe162770952746e40d425533",
     "grade": true,
     "grade_id": "A-1a",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(MR_df, pd.DataFrame)\n",
    "assert list(MR_df.columns) == ['index', 'label', 'review']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "22306bbac34884ea61b62b1693ee4d9a",
     "grade": false,
     "grade_id": "cell-40dae07b7eed27b1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8477</td>\n",
       "      <td>neg</td>\n",
       "      <td>except as an acting exercise or an exceptional...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4031</td>\n",
       "      <td>pos</td>\n",
       "      <td>japanese director shohei imamura 's latest fil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10240</td>\n",
       "      <td>neg</td>\n",
       "      <td>i walked away not really know who `` they `` w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8252</td>\n",
       "      <td>neg</td>\n",
       "      <td>what could have been a neat little story about...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1346</td>\n",
       "      <td>pos</td>\n",
       "      <td>no screen fantasy-adventure in recent memory h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index label                                             review\n",
       "0   8477   neg  except as an acting exercise or an exceptional...\n",
       "1   4031   pos  japanese director shohei imamura 's latest fil...\n",
       "2  10240   neg  i walked away not really know who `` they `` w...\n",
       "3   8252   neg  what could have been a neat little story about...\n",
       "4   1346   pos  no screen fantasy-adventure in recent memory h..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the data\n",
    "MR_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b) String labels to numerical\n",
    "Create a function that converts string labels to numerical labels\n",
    "\n",
    "Function name: `convert_label`\n",
    "\n",
    "The function should do the following:\n",
    "- if the input label is \"pos\" return 1.0\n",
    "- if the input label is \"neg\" return 0.0\n",
    "- otherwise, return the input label as is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "37febbc56518b6539d6d6e2a177833b8",
     "grade": false,
     "grade_id": "Q-1b",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def convert_label(label):\n",
    "    if label ==\"pos\":\n",
    "        output=1.0\n",
    "    elif label==\"neg\":\n",
    "        output=0.0\n",
    "    else: \n",
    "        output=label\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a93eeacd8bf8339f6ccaee9a0378b406",
     "grade": true,
     "grade_id": "A-1b",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert callable(convert_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c) \n",
    "Convert all labels in `MR_df[\"label\"]` to numerical labels, using the `convert_label` function\n",
    "\n",
    "Save them as a new column named \"y\" in MR_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4daa25502cde5195c545154ed2009e33",
     "grade": false,
     "grade_id": "Q-1c",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "MR_df[\"y\"]=MR_df[\"label\"].apply(convert_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0416a6af906712715050d5db1e69c54b",
     "grade": true,
     "grade_id": "A-1c",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert set(MR_df['y']) == { 0., 1. }\n",
    "# Check for roughly the right labels\n",
    "assert 0.3 < MR_df['y'].mean() < 0.7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "851347cca7a104f450a70082311a2a1f",
     "grade": false,
     "grade_id": "cell-cd37ee3f688aaaec",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8477</td>\n",
       "      <td>neg</td>\n",
       "      <td>except as an acting exercise or an exceptional...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4031</td>\n",
       "      <td>pos</td>\n",
       "      <td>japanese director shohei imamura 's latest fil...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10240</td>\n",
       "      <td>neg</td>\n",
       "      <td>i walked away not really know who `` they `` w...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8252</td>\n",
       "      <td>neg</td>\n",
       "      <td>what could have been a neat little story about...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1346</td>\n",
       "      <td>pos</td>\n",
       "      <td>no screen fantasy-adventure in recent memory h...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index label                                             review    y\n",
       "0   8477   neg  except as an acting exercise or an exceptional...  0.0\n",
       "1   4031   pos  japanese director shohei imamura 's latest fil...  1.0\n",
       "2  10240   neg  i walked away not really know who `` they `` w...  0.0\n",
       "3   8252   neg  what could have been a neat little story about...  0.0\n",
       "4   1346   pos  no screen fantasy-adventure in recent memory h...  1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the MR_df data\n",
    "MR_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1d) Convert Text data into vector \n",
    "\n",
    "We will now create a \"CountVectorizer\" object to transform the text data into vectors with numerical values. \n",
    "\n",
    "To do so, we will initialize a \"CountVectorizer\" object, and name it as \"vectorizer\".\n",
    "\n",
    "We need to pass 4 arguments to initialize a CountVectorizer:\n",
    "  1. analyzer: 'word'\n",
    "       Specify to analyze data from word-level\n",
    "  2. max_features: 2000\n",
    "       Set a max number of unique words\n",
    "  3. tokenizer: word_tokenize\n",
    "       Set to tokenize the text data by using the word_tokenizer from NLTK \n",
    "  4. stop_words: stopwords.words('english')\n",
    "       Set to remove all stopwords in English. We do this since they generally don't provide useful discriminative information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "b9a46f710926e62bd3c0bce5c787892c",
     "grade": false,
     "grade_id": "Q-1d",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "vectorizer = CountVectorizer(analyzer=\"word\", max_features=2000, tokenizer=word_tokenize, stop_words=stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f4a2bc9c2a6bc8e7c606c66eb1037ac3",
     "grade": true,
     "grade_id": "A-1d",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert vectorizer.analyzer == 'word'\n",
    "assert vectorizer.max_features == 2000\n",
    "assert vectorizer.tokenizer == word_tokenize\n",
    "assert vectorizer.stop_words == stopwords.words('english')\n",
    "assert hasattr(vectorizer, \"fit_transform\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1e) \n",
    "\n",
    "Transform reviews (`MR_df[\"review\"])` into vectors using the \"vectorizer\" we created above:\n",
    "\n",
    "The method you will be using is: `MR_X = vectorizer.fit_transform(...).toarray()`\n",
    "\n",
    "Note that we apply the `toarray` method at the type cast the output to a numpy array. This is something we will do multiple times, to turn custom sklearn objects back into arrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "40b2b185e93055aca4dbbcf0559f5feb",
     "grade": false,
     "grade_id": "Q-1e",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zafri\\Anaconda2\\envs\\py36\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:286: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'might', 'must', \"n't\", 'need', 'sha', 'wo', 'would'] not in stop_words.\n",
      "  sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "MR_X = vectorizer.fit_transform(MR_df[\"review\"]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ec1fecbf168063a272cc960eac635ab4",
     "grade": true,
     "grade_id": "A-1e",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(MR_X) == np.ndarray\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1f) \n",
    "\n",
    "Copy out `y` column in MR_df and save it as an np.ndarray named `MR_y`\n",
    "\n",
    "Make sure the shape of `MR_y` is (5000,) - you may have to use `reshape` to do so. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a5009eb093ce369b056100d05aed0df5",
     "grade": false,
     "grade_id": "Q-1f",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000,)\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "MR_y=MR_df.iloc[:,3].as_matrix()\n",
    "print (MR_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3b15f7368fa336b9430b03d8f6988d63",
     "grade": true,
     "grade_id": "A-1f",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert MR_y.shape == (5000,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1g) Split up train and test sets\n",
    "We first set 80% of the data as the training set to train an SVM classifier. We will then test the learnt classifier on the rest 20% data samples.\n",
    "\n",
    "- Calculate the number of training data samples (80% of total) and store it in `num_training`\n",
    "- Calculate the number of test data samples (20% of total) and store it in `num_testing`\n",
    "- Make sure both of these variables are of type `int`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e298ab23819a9a4594044f2a0093de8d",
     "grade": false,
     "grade_id": "Q-1g",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000 1000\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "rows,cols=MR_df.shape\n",
    "num_training=int(rows*(.8))\n",
    "num_testing=int(rows*(.2))\n",
    "print (num_training, num_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6c26caa14ff22dbcfc8f8888b2b98d6d",
     "grade": true,
     "grade_id": "A-1g",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(num_training) == int\n",
    "assert type(num_testing) == int\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1h) \n",
    "\n",
    "Split the `MR_X` and `MR_y` into training set and test set. You should use the `num_training` variable to extract the data from MR_X and MR_y.\n",
    "     \n",
    "Extract the first 'num_training' samples as training data, and extract the rest as test data.\n",
    "\n",
    "Name them as:\n",
    "- `MR_train_X` and `MR_train_y` for the training set\n",
    "- `MR_test_X` and `MR_test_y` for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d888930edf9ab8fd0615327486450959",
     "grade": false,
     "grade_id": "Q-1h",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is everything the right shape?        True\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "#train\n",
    "MR_train_X=MR_X[0:num_training]\n",
    "MR_train_y=MR_y[0:num_training]\n",
    "#test\n",
    "MR_test_X=MR_X[num_training:]\n",
    "MR_test_y=MR_y[num_training:]\n",
    "print (\"Is everything the right shape?       \",len(MR_test_X)==len(MR_test_y)==num_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "394846299466a6fc67650c96a45664e7",
     "grade": true,
     "grade_id": "A-1h",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert MR_train_X.shape[0] == MR_train_y.shape[0]\n",
    "assert MR_test_X.shape[0] == MR_test_y.shape[0]\n",
    "\n",
    "assert len(MR_train_X) == 4000\n",
    "assert len(MR_test_y) == 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1i) SVM\n",
    "\n",
    "Define a function called `train_SVM` that initializes an SVM classifier and trains it\n",
    "\n",
    "Inputs: \n",
    "- `X`: np.ndarray, training samples, \n",
    "- `y`: np.ndarray, training labels,\n",
    "- `kernel`: string, set the default value of \"kernel\" as \"linear\"\n",
    "\n",
    "Output: a trained classifier `clf`\n",
    "\n",
    "Hint: There are 2 steps involved in this function:\n",
    "- Initializing an SVM classifier: `clf = SVC(...)`\n",
    "- Training the classifier: `clf.fit(X, y)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "5fbfdd5a9069ab146b47c82776b71e71",
     "grade": false,
     "grade_id": "Q-1i",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def train_SVM(X, y, kernel='linear'):\n",
    "    clf= SVC(kernel=kernel)\n",
    "    clf.fit(X, y)\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "55eb758d448afee6160529b9960da8ac",
     "grade": true,
     "grade_id": "A-1i",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert callable(train_SVM)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1j) Train SVM\n",
    "\n",
    "Train an SVM classifier on the samples `MR_train_X` and the labels `MR_train_y`\n",
    "\n",
    "You need to call the function `train_SVM` you just created. Name the returned object as `MR_clf`.\n",
    "\n",
    "Note that running this function may take many seconds / up to a few minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "045b0b73c674e9ea174a52a6159cd14d",
     "grade": false,
     "grade_id": "Q-ij",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "MR_clf=train_SVM(MR_train_X, MR_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d527fd33a6355256100c77d493ffec4e",
     "grade": true,
     "grade_id": "A-ij",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(MR_clf, SVC)\n",
    "assert hasattr(MR_clf, \"predict\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1k) \n",
    "\n",
    "Predict labels for both training samples and test samples. You will need to use `MR_clf.predict(...)`\n",
    "\n",
    "Name the predicted labels for the training samples as `MR_predicted_train_y`.\n",
    "Name the predicted labels for the testing samples as `MR_predicted_test_y`.\n",
    "\n",
    "Your code here will also take a minute to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "92659f65db8bb439049106ef91a1de1b",
     "grade": false,
     "grade_id": "Q-k",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "MR_predicted_train_y=MR_clf.predict(MR_train_X)\n",
    "MR_predicted_test_y=MR_clf.predict(MR_test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "975855c61de091efe8eb52181efc8e80",
     "grade": false,
     "grade_id": "cell-fc5799e344e24b69",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.92      0.91      2008\n",
      "         1.0       0.92      0.91      0.91      1992\n",
      "\n",
      "   micro avg       0.91      0.91      0.91      4000\n",
      "   macro avg       0.91      0.91      0.91      4000\n",
      "weighted avg       0.91      0.91      0.91      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now we will use the function 'classification_report'\n",
    "#  to print out the performance of the classifier on the training set\n",
    "\n",
    "# Your classifier should be able to reach above 90% accuracy on the training set\n",
    "print(classification_report(MR_train_y,MR_predicted_train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c836592afff80898804c801bd2e21d6a",
     "grade": true,
     "grade_id": "A-1k",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Tests for 1k\n",
    "assert MR_predicted_train_y.shape == (4000,)\n",
    "assert MR_predicted_test_y.shape == (1000,)\n",
    "\n",
    "precision, recall, _, _ = precision_recall_fscore_support(MR_train_y,MR_predicted_train_y)\n",
    "assert np.isclose(precision[0], 0.91, 0.02)\n",
    "assert np.isclose(precision[1], 0.92, 0.02)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ab144d1f5f428088d3dbb25acfd27bf5",
     "grade": false,
     "grade_id": "cell-9fc925527bb32076",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.68      0.69       482\n",
      "         1.0       0.71      0.72      0.72       518\n",
      "\n",
      "   micro avg       0.70      0.70      0.70      1000\n",
      "   macro avg       0.70      0.70      0.70      1000\n",
      "weighted avg       0.70      0.70      0.70      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# And finally, we check the performance of the trained classifier on the test set\n",
    "\n",
    "# Your classifier should be able to reach around 70% accuracy on the test set.\n",
    "print(classification_report(MR_test_y, MR_predicted_test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "592f6be991c7a20c59314ff39989da9b",
     "grade": false,
     "grade_id": "cell-1f649bb709859c3e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Part 2: TF-IDF\n",
    "\n",
    "In this part, we will explore TF-IDF on sentiment analysis.\n",
    "\n",
    "TF-IDF is used as an alternate way to encode text data, as compared to the BoW's approach used in Part 1. \n",
    "\n",
    "To do, we will:\n",
    "- Transform the raw text data into vectors using TF-IDF\n",
    "- Train an SVM classifier on the training set and report the performance this classifer on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a) Text Data to Vectors\n",
    "\n",
    "We will create a \"TfidfVectorizer\" object to transform the text data into vectors with TF-IDF\n",
    "\n",
    "To do so, we will initialize a \"TfidfVectorizer\" object, and name it as \"tfidf\".\n",
    "\n",
    "We need to pass 4 arguments into the \"TfidfVectorizer\" to initialize a \"tfidf\":\n",
    "  1. sublinear_tf: True\n",
    "       Set to apply TF scaling.\n",
    "  2. analyzer: 'word'\n",
    "       Set to analyze the data at the word-level\n",
    "  3. max_features: 2000\n",
    "       Set the max number of unique words\n",
    "  4. tokenizer: word_tokenize\n",
    "       Set to tokenize the text data by using the word_tokenizer from NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ce1bcc99352ae5525881d3bbf044ec70",
     "grade": false,
     "grade_id": "Q-2a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "tfidf=TfidfVectorizer(sublinear_tf=True, analyzer=\"word\", \n",
    "                      max_features=2000, tokenizer=word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6d607d89e0d3ffcece40dd78cccb5a55",
     "grade": true,
     "grade_id": "A-2a",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert tfidf.analyzer == 'word'\n",
    "assert tfidf.max_features == 2000\n",
    "assert tfidf.tokenizer == word_tokenize\n",
    "assert tfidf.stop_words == None\n",
    "assert hasattr(vectorizer, \"fit_transform\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b) Transform Reviews \n",
    "\n",
    "Transform the `review` column of MR_df into vectors using the `tfidf` we created above.\n",
    "\n",
    "Save the transformed data into a variable called `MR_tfidf_X`\n",
    "\n",
    "Hint: You might need to cast the datatype of `MR_tfidf_X` to `numpy.ndarray` by using `.toarray()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "025ea6833ba6f4df312c31deaa497e2d",
     "grade": false,
     "grade_id": "Q-2b",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "MR_tfidf_X = tfidf.fit_transform(MR_df[\"review\"]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5e419cca933997eed3404edc0224a311",
     "grade": true,
     "grade_id": "A-2b",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(MR_tfidf_X, np.ndarray)\n",
    "\n",
    "assert \"skills\" in set(tfidf.stop_words_)\n",
    "assert \"risky\" in set(tfidf.stop_words_)\n",
    "assert \"adopts\" in set(tfidf.stop_words_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c) \n",
    "Split the `MR_tfidf_X` and `MR_y` into training set and test set. \n",
    "\n",
    "Name these variables as:\n",
    "- `MR_train_tfidf_X` and `MR_train_tfidf_y` for the training set\n",
    "- `MR_test_tfidf_X` and `MR_test_tfidf_y` for the test set\n",
    "\n",
    "We will use the same 80/20 split as in part 1. You can use the same `num_training` variable from part 1 to split up the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "591708dbcc5c302cd7676f072937d4e8",
     "grade": false,
     "grade_id": "Q-2c",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is everything the right shape?        True\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "#train\n",
    "MR_train_tfidf_X=MR_tfidf_X[0:num_training]\n",
    "MR_train_tfidf_y=MR_y[0:num_training]\n",
    "#test\n",
    "MR_test_tfidf_X=MR_tfidf_X[num_training:]\n",
    "MR_test_tfidf_y=MR_y[num_training:]\n",
    "print (\"Is everything the right shape?       \",len(MR_test_X)==len(MR_test_y)==num_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c6e5d24c12ad756d5ec0d4e12e0fa7e7",
     "grade": true,
     "grade_id": "A-2c",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert MR_train_tfidf_X[0].tolist() == MR_tfidf_X[0].tolist()\n",
    "assert MR_train_tfidf_X.shape == (4000, 2000)\n",
    "assert MR_test_tfidf_X.shape == (1000, 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2d) Training\n",
    "\n",
    "Train an SVM classifier on the samples `MR_train_tfidf_X` and the labels `MR_train_y`.\n",
    "\n",
    "You need to call the function `train_SVM` you created in part 1. Name the returned object as `MR_tfidf_clf`.\n",
    "\n",
    "Note that this may take many seconds, up to a few minutes, to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "6eb6e10b5381e26bae6627ed77281b85",
     "grade": false,
     "grade_id": "Q-2d",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "MR_tfidf_clf=train_SVM(MR_train_tfidf_X, MR_train_tfidf_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "cb5d311cc8b088971b1b20fd1e14301f",
     "grade": true,
     "grade_id": "A-2d",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(MR_clf, SVC)\n",
    "assert hasattr(MR_tfidf_clf, \"predict\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2e) Prediction\n",
    "\n",
    "Predict the labels for both the training and test samples (the 'X' data). You will need to use `MR_tfidf_clf.predict(...)`\n",
    "\n",
    "Name the predicted labels on training samples as `MR_pred_train_tfidf_y`. Name the predicted labels on testing samples as `MR_pred_test_tfidf_y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "816245b11f565460b7f1b8bff30b150d",
     "grade": false,
     "grade_id": "Q-2e",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "MR_pred_train_tfidf_y=MR_tfidf_clf.predict(MR_train_tfidf_X)\n",
    "MR_pred_test_tfidf_y=MR_tfidf_clf.predict(MR_test_tfidf_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e435a2f2352cca1073ce66f4a7bfa4d7",
     "grade": false,
     "grade_id": "cell-afa1a0e6e8f72a98",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.88      0.87      2008\n",
      "         1.0       0.87      0.85      0.86      1992\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      4000\n",
      "   macro avg       0.87      0.87      0.87      4000\n",
      "weighted avg       0.87      0.87      0.87      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Again, we use 'classification_report' to check the performance on the training set \n",
    "\n",
    "# Your classifier should be able to reach above 85% accuracy.\n",
    "print(classification_report(MR_train_tfidf_y, MR_pred_train_tfidf_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8aa3a7db72cd3b5a8208c12fb4e35124",
     "grade": true,
     "grade_id": "A-2e",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Tests for 2e\n",
    "precision, recall, _, _ = precision_recall_fscore_support(MR_train_tfidf_y, MR_pred_train_tfidf_y)\n",
    "assert np.isclose(precision[0], 0.86, 0.02)\n",
    "assert np.isclose(precision[1], 0.87, 0.02)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "577fe1deb6fd1b240c0e02a4c08c36a0",
     "grade": false,
     "grade_id": "cell-0d6895d998434cbe",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.72      0.72       482\n",
      "         1.0       0.74      0.74      0.74       518\n",
      "\n",
      "   micro avg       0.73      0.73      0.73      1000\n",
      "   macro avg       0.73      0.73      0.73      1000\n",
      "weighted avg       0.73      0.73      0.73      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# And check performance on the test set\n",
    "\n",
    "# Your classifier should be able to reach around 70% accuracy.\n",
    "print(classification_report(MR_test_tfidf_y, MR_pred_test_tfidf_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1b62782d33e5022d26d18ec60b5a457f",
     "grade": false,
     "grade_id": "cell-15bf17c90c32702a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Part 3: Sentiment Analysis on Customer Review with TF-IDF\n",
    "\n",
    "In this part, we will use TF-IDF to analyse the sentiment of some Customer Review (CR) data.\n",
    "\n",
    "The CR data contains around 3771 reviews, and they were all collected from the Amazon website. The reviews are annotated by human as either positive reviews and negative reviews. In this dataset, the 2 classes are not balanced, as there are twice as many positive reviews as negative reviews.\n",
    "\n",
    "For more information on this dataset, you can visit https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html\n",
    "\n",
    "In this part, we have alreay split the data into a training set and a test set, in which the training set has labels for the reviews, but the test set doesn't. \n",
    "\n",
    "The goal is to train an SVM classifier on the training set, and then predict pos/neg for each review in the test set.\n",
    "\n",
    "To do so, we will:\n",
    "- Use the TF-IDF feature engineering method to encode the raw text data into vectors\n",
    "- Train an SVM classifier on the training set\n",
    "- Predict labels for the reviews in the test set\n",
    "\n",
    "The performance of your trained classifier on the test set will be checked by a hidden test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a) Loading the data\n",
    "\n",
    "Customer review task has 2 files\n",
    "- \"data/custrev.tsv\" contains training data with labels\n",
    "- \"data/custrev.tsv\" contains test data without labels which need to be predicted \n",
    "\n",
    "Import raw textfile `data/custrev.train` into a DataFrame called `CR_train_df`. Set the column names as `index`, `label`, `review`.\n",
    "\n",
    "Import raw textfile `data/custrev.test` into a DataFrame called `CR_test_df`. Set the column names as `index`, `review`\n",
    "\n",
    "Note that both will need to be imported with `sep` and `header` arguments (like in 1a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "02ce63808d461bfad89daff819acb92d",
     "grade": false,
     "grade_id": "Q-3a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "CR_train_file='data/custrev_train.tsv'\n",
    "CR_test_file = 'data/custrev_test.tsv'\n",
    "\n",
    "# YOUR CODE HERE\n",
    "CR_train_df=pd.read_csv(CR_train_file, sep='\\t', header=None, names=['index', 'label', 'review'])\n",
    "CR_test_df=pd.read_csv(CR_test_file, sep='\\t', header=None, names=['index', 'review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "42a04c67c8f361f41ee158b5e5faf6b5",
     "grade": true,
     "grade_id": "A-3a",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(CR_train_df, pd.DataFrame)\n",
    "assert list(CR_train_df.columns) == ['index', 'label', 'review']\n",
    "assert CR_train_df.shape == (3016, 3)\n",
    "\n",
    "assert isinstance(CR_test_df, pd.DataFrame)\n",
    "assert list(CR_test_df.columns) == ['index', 'review']\n",
    "assert CR_test_df.shape == (755, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b) \n",
    "Concatenate 2 DataFrames into 1 DataFrame, and name it `CR_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "77cb9f91e11824e5f97cf895bdc4a1ae",
     "grade": false,
     "grade_id": "Q-3b",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3016, 3)\n",
      "(755, 2)\n",
      "(3771, 3)\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "print (CR_train_df.shape)\n",
    "print (CR_test_df.shape)\n",
    "CR_df=pd.concat([CR_train_df, CR_test_df])\n",
    "print (CR_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3f9c92dcaf4b13595f046a6f831dbe0e",
     "grade": true,
     "grade_id": "A-3b",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(CR_df) == 3771\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3c) \n",
    "\n",
    "Convert all labels in `CR_df[\"label\"]` using the function we defined above `convert_label`. Save these numerical labels as a new column named `y` in CR_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "0144c733efbb0bccdcff00556f828467",
     "grade": false,
     "grade_id": "Q-3c",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "CR_df[\"y\"]=CR_df['label'].apply(convert_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c913739a93d890af4fcde874cff4e29c",
     "grade": true,
     "grade_id": "A-3c",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(CR_df['y'], pd.Series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3d) \n",
    "\n",
    "Transform reviews `CR_df[\"review\"]` into vectors using the `tfidf` vectorizer we created in part 2. Save the transformed data into a variable called `CR_tfidf_X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "f9b5a50a8bfd01d1a84335933c17e079",
     "grade": false,
     "grade_id": "Q-3d",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "CR_tfidf_X = tfidf.fit_transform(CR_df[\"review\"]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "84b230edd88d03b60142c2d18f3a793e",
     "grade": true,
     "grade_id": "A-3d",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(CR_tfidf_X, np.ndarray)\n",
    "assert CR_tfidf_X.shape == (3771, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "138fea75f0adbf13da2b77dfaea83b0e",
     "grade": false,
     "grade_id": "get_data",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Here we will collect all training samples & numerical labels from CR_tfidf_X [code provided]\n",
    "#   The code provided below will extract all samples with labels from the dataframe\n",
    "\n",
    "CR_train_X = CR_tfidf_X[~CR_df['y'].isnull()]\n",
    "CR_train_y = CR_df['y'][~CR_df['y'].isnull()]\n",
    "\n",
    "# Note: if these asserts fail, something went wrong\n",
    "#  Go back and check your code (in part 3) above this cell\n",
    "assert CR_train_X.shape == (3016, 2000)\n",
    "assert CR_train_y.shape == (3016, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3e) \n",
    "\n",
    "Train an SVM classifier on the samples `CR_train_X` and the labels `CR_train_y`\n",
    "- You need to call the function `train_SVM` you created above.\n",
    "- Name the returned object as `CR_clf`.\n",
    "- Note that this function will take many seconds / up to a few minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "d7b2307c4b5cb41d418554659d2ef781",
     "grade": false,
     "grade_id": "Q-3e",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "CR_clf=train_SVM(CR_train_X, CR_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1a9250c5705606e504c15597175657ee",
     "grade": true,
     "grade_id": "A-3e",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(CR_clf, SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3f) \n",
    "\n",
    "Predict labels on the training set, and name the returned variable as `CR_pred_train_y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "a8514b0192f4492cf745a2884bb50f09",
     "grade": false,
     "grade_id": "Q-3f",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "CR_pred_train_y=CR_clf.predict(CR_train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d0c54b282080ec83c81b76b537bc32de",
     "grade": false,
     "grade_id": "cell-5393293deccc9d78",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.84      0.87      1097\n",
      "         1.0       0.91      0.95      0.93      1919\n",
      "\n",
      "   micro avg       0.91      0.91      0.91      3016\n",
      "   macro avg       0.91      0.89      0.90      3016\n",
      "weighted avg       0.91      0.91      0.91      3016\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the classifier accuracy on the train data\n",
    "#   Note that your classifier should be able to reach above 90% accuracy.\n",
    "print(classification_report(CR_train_y, CR_pred_train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "dab7a4c970b847e5a97e5b5a7f4c6766",
     "grade": true,
     "grade_id": "A-3f",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Tests for 3f\n",
    "precision, recall, _, _ = precision_recall_fscore_support(CR_train_y, CR_pred_train_y)\n",
    "assert np.isclose(precision[0], 0.90, 0.02)\n",
    "assert np.isclose(precision[1], 0.91, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1b5df6600b7e7dd3c737ecc0ee81a950",
     "grade": false,
     "grade_id": "cell-8fd0d23508a04891",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Collect all test samples from CR_tfidf_X\n",
    "CR_test_X = CR_tfidf_X[CR_df['y'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3g) \n",
    "Predict the labels on the test set. Name the returned variable as `CR_pred_test_y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "b65addc59fa4490663b6e3a64f99b74f",
     "grade": false,
     "grade_id": "Q-3g",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "CR_pred_test_y=CR_clf.predict(CR_test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c9ce7c1d4cf51848d1c73cd06a6269a2",
     "grade": true,
     "grade_id": "A-3g",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(CR_test_X, np.ndarray)\n",
    "assert isinstance(CR_pred_test_y, np.ndarray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3h) \n",
    "\n",
    "Convert the predicted numerical labels back to string labels.\n",
    "\n",
    "Create a column called `label` in `CR_test_df` to store the converted labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "dffb957468c0c3f47c0d9ad1d4043078",
     "grade": false,
     "grade_id": "Q-3h",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1.,\n",
       "       1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
       "       1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,\n",
       "       0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "       0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "       0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,\n",
       "       1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,\n",
       "       1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,\n",
       "       1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
       "       1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "       0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0.,\n",
       "       1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,\n",
       "       1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
       "       0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1.,\n",
       "       1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
       "       1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1.,\n",
       "       1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0.,\n",
       "       1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,\n",
       "       1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,\n",
       "       0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1.,\n",
       "       0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
       "       1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
       "       1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
       "       1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "       1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,\n",
       "       1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
       "       0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,\n",
       "       1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0.,\n",
       "       1., 1., 0., 0., 1., 1., 0.])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "def convert_label_tostr(label):\n",
    "    if label ==1.0:\n",
    "        output=\"pos\"\n",
    "    elif label==0:\n",
    "        output=\"neg\"\n",
    "    else: \n",
    "        output=label\n",
    "    return output\n",
    "\n",
    "\n",
    "CR_pred_test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_label=[convert_label_tostr(i) for i in CR_pred_test_y]\n",
    "CR_test_df[\"label\"]=string_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e32bdf404a55ba5453d5bbd05209560d",
     "grade": true,
     "grade_id": "A-3h",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(CR_test_df['label'], pd.Series)\n",
    "assert set(CR_test_df['label']) == {'neg', 'pos'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
